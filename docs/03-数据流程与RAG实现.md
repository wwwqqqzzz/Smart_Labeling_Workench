# æ•°æ®æµç¨‹ä¸ RAG å®ç°

## ğŸ“Š æ•°æ®æµç¨‹è®¾è®¡

### 1. æ•°æ®å¯¼å…¥æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Excel æ–‡ä»¶ (1.xlsx)                                         â”‚
â”‚  - Sheet1: æ‰“æ ‡1æœˆ1æœŸ (å¯¹è¯æ•°æ®)                            â”‚
â”‚  - Sheet2: æ ‡å‡†åŒ–æ ‡ç­¾ (æ ‡ç­¾å®šä¹‰)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: è¯»å– Excel                                          â”‚
â”‚  - pandas.read_excel()                                      â”‚
â”‚  - è§£æå¯¹è¯æ•°æ®ï¼ˆ3500 æ¡ï¼‰                                  â”‚
â”‚  - è§£ææ ‡ç­¾å®šä¹‰ï¼ˆ56 ä¸ªï¼‰                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: æ•°æ®æ¸…æ´—                                            â”‚
â”‚  - å»é™¤ç©ºæ ¼ã€æ¢è¡Œç¬¦                                         â”‚
â”‚  - éªŒè¯ JSON æ ¼å¼                                          â”‚
â”‚  - å¤„ç†å¼‚å¸¸æ•°æ®                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: æ•°æ®åº“æŒä¹…åŒ–                                        â”‚
â”‚  - å­˜å…¥ conversations è¡¨                                    â”‚
â”‚  - å­˜å…¥ tags è¡¨                                             â”‚
â”‚  - å»ºç«‹ç´¢å¼•                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: æ„å»ºå‘é‡åº“                                          â”‚
â”‚  - ä¸ºæ¯ä¸ªæ ‡ç­¾å®šä¹‰ç”ŸæˆåµŒå…¥å‘é‡                               â”‚
â”‚  - å­˜å…¥ Chroma å‘é‡åº“                                       â”‚
â”‚  - å»ºç«‹ç´¢å¼•                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. å®¡æ ¸å·¥ä½œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·æ‰“å¼€ç•Œé¢                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯ï¼šåŠ è½½å¾…å®¡æ ¸å¯¹è¯                                         â”‚
â”‚  GET /api/v1/conversations?status=pending&page=1           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯ï¼šè§£æå¯¹è¯æ–‡æœ¬                                          â”‚
â”‚  - æŒ‰ $_$ åˆ†å‰²                                             â”‚
â”‚  - è¯†åˆ«å¸æœº/è´§ä¸»                                            â”‚
â”‚  - é«˜äº®å…³é”®è¯                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯ï¼šè§¦å‘ RAG æ¨èï¼ˆå¼‚æ­¥ï¼‰                                 â”‚
â”‚  POST /api/v1/rag/check                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åç«¯ï¼šRAG å¼•æ“å¤„ç†                                          â”‚
â”‚  1. å‘é‡æ£€ç´¢ç›¸å…³æ ‡ç­¾å®šä¹‰                                    â”‚
â”‚  2. LLM åˆ¤æ–­ AI æ ‡ç­¾æ˜¯å¦æ­£ç¡®                               â”‚
â”‚  3. è¿”å›æ¨èç»“æœ                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯ï¼šæ˜¾ç¤ºæ¨èç»“æœ                                          â”‚
â”‚  - ç½®ä¿¡åº¦æ˜¾ç¤º                                              â”‚
â”‚  - Top 3 æ¨èæ ‡ç­¾                                          â”‚
â”‚  - æ¨ç†è¿‡ç¨‹ï¼ˆå¯å±•å¼€ï¼‰                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·æ“ä½œ                                                    â”‚
â”‚  - æŒ‰ç©ºæ ¼ï¼šç¡®è®¤ AI æ ‡ç­¾                                     â”‚
â”‚  - æŒ‰ 1-3ï¼šé€‰æ‹©æ¨èæ ‡ç­¾                                     â”‚
â”‚  - ç‚¹å‡»æ ‡ç­¾ï¼šä»é€Ÿé€‰æ± é€‰æ‹©                                   â”‚
â”‚  - æŒ‰ Enterï¼šè·³è¿‡ï¼ˆå­˜ç–‘ï¼‰                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯ï¼šæäº¤å®¡æ ¸ç»“æœ                                          â”‚
â”‚  PUT /api/v1/conversations/:id                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åç«¯ï¼šä¿å­˜æ•°æ®                                             â”‚
â”‚  - æ›´æ–° conversations è¡¨                                   â”‚
â”‚  - è®°å½• audit_logs                                         â”‚
â”‚  - æ›´æ–°ç¼“å­˜                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯ï¼šè‡ªåŠ¨åŠ è½½ä¸‹ä¸€æ¡                                        â”‚
â”‚  é¢„å–ä¸‹ä¸€æ¡æ•°æ®ï¼Œæå‡ä½“éªŒ                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– RAG å®ç°ç»†èŠ‚

### å‘é‡åº“æ„å»º

#### 1. æ ‡ç­¾å®šä¹‰å‘é‡åŒ–

```python
# services/vector_store_builder.py
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.docstore.document import Document
from typing import List

class VectorStoreBuilder:
    """å‘é‡åº“æ„å»ºå™¨"""

    def __init__(self, persist_directory: str = "./data/chroma"):
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.persist_directory = persist_directory

    def build_from_tags(self, tags: List[Tag]) -> Chroma:
        """
        ä»æ ‡ç­¾åˆ—è¡¨æ„å»ºå‘é‡åº“

        Args:
            tags: æ ‡ç­¾åˆ—è¡¨

        Returns:
            Chroma å‘é‡åº“
        """
        # 1. æ„å»ºæ–‡æ¡£
        documents = []
        for tag in tags:
            # ç»„åˆæ ‡ç­¾åå’Œå®šä¹‰
            content = f"æ ‡ç­¾åï¼š{tag.name}\nå®šä¹‰ï¼š{tag.definition or 'æš‚æ— å®šä¹‰'}"

            doc = Document(
                page_content=content,
                metadata={
                    "tag_id": tag.id,
                    "tag_name": tag.name,
                    "category": tag.category,
                    "definition": tag.definition
                }
            )
            documents.append(doc)

        # 2. åˆ›å»ºå‘é‡åº“
        vector_store = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory=self.persist_directory,
            collection_name="tag_definitions"
        )

        # 3. æŒä¹…åŒ–
        vector_store.persist()

        return vector_store

    def load_existing(self) -> Chroma:
        """åŠ è½½å·²å­˜åœ¨çš„å‘é‡åº“"""
        return Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embeddings,
            collection_name="tag_definitions"
        )
```

#### 2. å‘é‡æ£€ç´¢ä¼˜åŒ–

```python
# rag/retriever.py
from typing import List, Optional
from rank_bm25 import BM25Okapi
import jieba

class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ï¼ˆå‘é‡ + BM25ï¼‰"""

    def __init__(
        self,
        vector_store: Chroma,
        tags: List[Tag],
        alpha: float = 0.7  # å‘é‡æƒé‡
    ):
        self.vector_store = vector_store
        self.tags = tags
        self.alpha = alpha

        # æ„å»º BM25 ç´¢å¼•
        self._build_bm25_index()

    def _build_bm25_index(self):
        """æ„å»º BM25 ç´¢å¼•"""
        corpus = []
        for tag in self.tags:
            # åˆ†è¯
            tokens = list(jieba.cut(tag.definition or tag.name))
            corpus.append(tokens)

        self.bm25 = BM25Okapi(corpus)
        self.corpus = corpus

    async def retrieve(
        self,
        query: str,
        top_k: int = 5
    ) -> List[TagWithScore]:
        """
        æ··åˆæ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å› Top K

        Returns:
            å¸¦åˆ†æ•°çš„æ ‡ç­¾åˆ—è¡¨
        """
        # 1. å‘é‡æ£€ç´¢
        vector_results = self.vector_store.similarity_search_with_score(
            query, k=top_k * 2
        )
        vector_scores = self._normalize_vector_scores(vector_results)

        # 2. BM25 æ£€ç´¢
        query_tokens = list(jieba.cut(query))
        bm25_scores = self.bm25.get_scores(query_tokens)

        # 3. æ··åˆæ’åº
        final_scores = {}
        for tag_name, vec_score in vector_scores.items():
            bm25_score = bm25_scores.get(tag_name, 0)
            # åŠ æƒèåˆ
            final_scores[tag_name] = (
                self.alpha * vec_score +
                (1 - self.alpha) * bm25_score
            )

        # 4. æ’åºå¹¶è¿”å› Top K
        sorted_tags = sorted(
            final_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:top_k]

        return [
            TagWithScore(
                name=tag_name,
                score=score,
                definition=self._get_definition(tag_name)
            )
            for tag_name, score in sorted_tags
        ]
```

### LLM åˆ¤æ–­å®ç°

#### Prompt å·¥ç¨‹è®¾è®¡

```python
# rag/prompts.py
from jinja2 import Template

CHECK_TAG_TEMPLATE = Template("""
ä½ æ˜¯ä¸€ä¸ªè´§è¿å¯¹è¯æ ‡ç­¾å®¡æ ¸ä¸“å®¶ã€‚ä½ éœ€è¦åˆ¤æ–­ AI è‡ªåŠ¨æ‰“çš„æ ‡ç­¾æ˜¯å¦æ­£ç¡®ã€‚

## å¯¹è¯å†…å®¹
{{ conversation_text }}

## AI è‡ªåŠ¨æ‰“çš„æ ‡ç­¾
{{ ai_tag }}

## å‚è€ƒæ ‡ç­¾å®šä¹‰
{% for tag in relevant_tags %}
### {{ tag.name }}
{{ tag.definition or 'æš‚æ— å®šä¹‰' }}
{% endfor %}

## åˆ¤æ–­æ ‡å‡†
1. **ä¸¥æ ¼åŒ¹é…**ï¼šå¯¹è¯å†…å®¹å¿…é¡»æ˜ç¡®ç¬¦åˆæ ‡ç­¾å®šä¹‰
2. **å®å¯æ¼æ‰“ï¼Œä¸å¯æ‰“é”™**ï¼šä¸ç¡®å®šçš„æƒ…å†µä¸‹ï¼Œåˆ¤å®šä¸ºä¸æ­£ç¡®
3. **å¤šæ ‡ç­¾æƒ…å†µ**ï¼šå¦‚æœå¯¹è¯æ¶‰åŠå¤šä¸ªæ ‡ç­¾ï¼ŒAI åªæ‰“äº†ä¸€ä¸ªï¼Œä¹Ÿç®—ä¸æ­£ç¡®

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
```json
{
  "is_correct": true/false,
  "confidence": 0.0-1.0,
  "recommendations": [
    {
      "tag": "æ ‡ç­¾åç§°",
      "score": 0.0-1.0,
      "reason": "æ¨èç†ç”±"
    }
  ],
  "reasoning": "è¯¦ç»†æ¨ç†è¿‡ç¨‹"
}
```

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯è¿›è¡Œåˆ¤æ–­ï¼Œå¹¶è¾“å‡º JSON æ ¼å¼ç»“æœã€‚
""")

class PromptManager:
    """Prompt ç®¡ç†å™¨"""

    @staticmethod
    def build_check_tag_prompt(
        conversation_text: str,
        ai_tag: str,
        relevant_tags: List[Tag]
    ) -> str:
        """æ„å»ºæ ‡ç­¾æ£€æŸ¥ Prompt"""
        return CHECK_TAG_TEMPLATE.render(
            conversation_text=conversation_text,
            ai_tag=ai_tag,
            relevant_tags=relevant_tags
        )
```

#### GLM-4 è°ƒç”¨

```python
# rag/llm_client.py
from zhipuai import ZhipuAI
from typing import List, Dict
import json

class GLMClient:
    """GLM-4 å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str):
        self.client = ZhipuAI(api_key=api_key)

    async def check_tag(
        self,
        conversation_text: str,
        ai_tag: str,
        relevant_tags: List[Tag]
    ) -> LLMJudgment:
        """
        ä½¿ç”¨ GLM-4 åˆ¤æ–­æ ‡ç­¾

        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            ai_tag: AI æ ‡ç­¾
            relevant_tags: ç›¸å…³æ ‡ç­¾å®šä¹‰

        Returns:
            LLM åˆ¤æ–­ç»“æœ
        """
        # 1. æ„å»º Prompt
        prompt = PromptManager.build_check_tag_prompt(
            conversation_text=conversation_text,
            ai_tag=ai_tag,
            relevant_tags=relevant_tags
        )

        # 2. è°ƒç”¨ GLM-4 Flash
        response = self.client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.1,  # ä½æ¸©åº¦ï¼Œä¿è¯ç¨³å®šæ€§
            max_tokens=1000
        )

        # 3. è§£æå“åº”
        result_text = response.choices[0].message.content

        # æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
        json_text = self._extract_json(result_text)

        try:
            result_data = json.loads(json_text)
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ä¿å®ˆç»“æœ
            return LLMJudgment(
                is_correct=False,
                confidence=0.0,
                recommendations=[],
                reasoning="LLM å“åº”è§£æå¤±è´¥"
            )

        # 4. æ„å»ºç»“æœ
        return LLMJudgment(
            is_correct=result_data.get("is_correct", False),
            confidence=result_data.get("confidence", 0.0),
            recommendations=[
                TagRecommendation(**rec)
                for rec in result_data.get("recommendations", [])
            ],
            reasoning=result_data.get("reasoning", "")
        )

    @staticmethod
    def _extract_json(text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå– JSON"""
        # å°è¯•ç›´æ¥è§£æ
        try:
            json.loads(text)
            return text
        except:
            pass

        # å°è¯•æå– ```json ... ```
        if "```json" in text:
            start = text.find("```json") + 7
            end = text.find("```", start)
            return text[start:end].strip()

        # å°è¯•æå– ``` ... ```
        if "```" in text:
            start = text.find("```") + 3
            end = text.find("```", start)
            return text[start:end].strip()

        # æå–ç¬¬ä¸€ä¸ª { ... }
        start = text.find("{")
        end = text.rfind("}") + 1
        return text[start:end]
```

### RAG å®Œæ•´æµç¨‹

```python
# rag/engine.py
from typing import Optional
import hashlib
import json

class RAGEngine:
    """RAG æ¨èå¼•æ“"""

    def __init__(
        self,
        retriever: HybridRetriever,
        llm_client: GLMClient,
        cache_client: Optional[Redis] = None
    ):
        self.retriever = retriever
        self.llm_client = llm_client
        self.cache = cache_client

    async def check_tag(
        self,
        conversation_text: str,
        ai_tag: str,
        use_cache: bool = True
    ) -> RAGResult:
        """
        æ£€æŸ¥ AI æ ‡ç­¾æ˜¯å¦æ­£ç¡®

        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            ai_tag: AI æ ‡ç­¾
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            RAG åˆ¤æ–­ç»“æœ
        """
        # 1. ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(
            conversation_text,
            ai_tag
        )

        # 2. æ£€æŸ¥ç¼“å­˜
        if use_cache and self.cache:
            cached_result = await self._get_from_cache(cache_key)
            if cached_result:
                return cached_result

        # 3. å‘é‡æ£€ç´¢
        relevant_tags = await self.retriever.retrieve(
            query=conversation_text,
            top_k=5
        )

        # 4. LLM åˆ¤æ–­
        llm_judgment = await self.llm_client.check_tag(
            conversation_text=conversation_text,
            ai_tag=ai_tag,
            relevant_tags=relevant_tags
        )

        # 5. æ„å»ºç»“æœ
        result = RAGResult(
            conversation_text=conversation_text,
            ai_tag=ai_tag,
            is_correct=llm_judgment.is_correct,
            confidence=llm_judgment.confidence,
            recommendations=llm_judgment.recommendations,
            reasoning=llm_judgment.reasoning,
            relevant_tags=relevant_tags
        )

        # 6. ç¼“å­˜ç»“æœ
        if use_cache and self.cache:
            await self._save_to_cache(cache_key, result)

        return result

    def _generate_cache_key(
        self,
        conversation_text: str,
        ai_tag: str
    ) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{conversation_text}:{ai_tag}"
        hash_value = hashlib.md5(content.encode()).hexdigest()
        return f"rag:result:{hash_value}"

    async def _get_from_cache(
        self,
        cache_key: str
    ) -> Optional[RAGResult]:
        """ä»ç¼“å­˜è·å–ç»“æœ"""
        try:
            cached_data = await self.cache.get(cache_key)
            if cached_data:
                return RAGResult.parse_raw(cached_data)
        except Exception as e:
            logger.warning(f"Cache get failed: {e}")
        return None

    async def _save_to_cache(
        self,
        cache_key: str,
        result: RAGResult
    ):
        """ä¿å­˜ç»“æœåˆ°ç¼“å­˜"""
        try:
            await self.cache.set(
                cache_key,
                result.json(),
                ex=3600  # 1 å°æ—¶è¿‡æœŸ
            )
        except Exception as e:
            logger.warning(f"Cache save failed: {e}")
```

---

## ğŸ¯ å‰ç«¯æ•°æ®æµ

### React Query æ•°æ®ç®¡ç†

```typescript
// hooks/useConversation.ts
import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'

export function useConversation(id: number) {
  return useQuery({
    queryKey: ['conversation', id],
    queryFn: async () => {
      const res = await fetch(`/api/v1/conversations/${id}`)
      return res.json()
    }
  })
}

export function useRAGCheck() {
  const queryClient = useQueryClient()

  return useMutation({
    mutationFn: async (params: {
      conversation_id: number
      conversation_text: string
      ai_tag: string
    }) => {
      const res = await fetch('/api/v1/rag/check', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(params)
      })
      return res.json()
    },
    onSuccess: (data) => {
      // æ›´æ–°ç¼“å­˜
      queryClient.setQueryData(
        ['rag', data.conversation_id],
        data
      )
    }
  })
}

export function useUpdateConversation() {
  const queryClient = useQueryClient()

  return useMutation({
    mutationFn: async ({
      id,
      ...data
    }: {
      id: number
      manual_tag?: string[]
      status?: string
      auditor?: string
    }) => {
      const res = await fetch(`/api/v1/conversations/${id}`, {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(data)
      })
      return res.json()
    },
    onSuccess: () => {
      // ä½¿ç¼“å­˜å¤±æ•ˆï¼Œè§¦å‘é‡æ–°è·å–
      queryClient.invalidateQueries({ queryKey: ['conversations'] })
    }
  })
}
```

### Zustand çŠ¶æ€ç®¡ç†

```typescript
// stores/auditStore.ts
import { create } from 'zustand'

interface AuditStore {
  // å½“å‰å®¡æ ¸çš„å¯¹è¯ ID
  currentConversationId: number | null

  // RAG æ¨èç»“æœ
  ragResult: RAGResult | null

  // æ“ä½œ
  setCurrentConversationId: (id: number | null) => void
  setRAGResult: (result: RAGResult | null) => void

  // å¿«æ·é”®æ“ä½œ
  approveAI: () => void
  selectRecommendation: (index: number) => void
  skipConversation: () => void
}

export const useAuditStore = create<AuditStore>((set, get) => ({
  currentConversationId: null,
  ragResult: null,

  setCurrentConversationId: (id) => set({ currentConversationId: id }),

  setRAGResult: (result) => set({ ragResult: result }),

  approveAI: () => {
    const { currentConversationId } = get()
    if (!currentConversationId) return

    // è°ƒç”¨æ›´æ–° API
    updateConversation({
      id: currentConversationId,
      manual_tag: [],  // ä½¿ç”¨ AI æ ‡ç­¾
      status: 'approved'
    })

    // åŠ è½½ä¸‹ä¸€æ¡
    const nextId = currentConversationId + 1
    set({ currentConversationId: nextId })
  },

  selectRecommendation: (index) => {
    const { ragResult, currentConversationId } = get()
    if (!ragResult || !currentConversationId) return

    const selectedTag = ragResult.recommendations[index]?.tag
    if (!selectedTag) return

    // æ›´æ–°æ ‡ç­¾
    updateConversation({
      id: currentConversationId,
      manual_tag: [selectedTag],
      status: 'approved'
    })

    // åŠ è½½ä¸‹ä¸€æ¡
    const nextId = currentConversationId + 1
    set({ currentConversationId: nextId })
  },

  skipConversation: () => {
    const { currentConversationId } = get()
    if (!currentConversationId) return

    // æ ‡è®°ä¸ºè·³è¿‡
    updateConversation({
      id: currentConversationId,
      status: 'skipped'
    })

    // åŠ è½½ä¸‹ä¸€æ¡
    const nextId = currentConversationId + 1
    set({ currentConversationId: nextId })
  }
}))
```

---

**æœ€åæ›´æ–°**: 2025-01-13
**ç»´æŠ¤è€…**: Smart Labeling Workbench Team
